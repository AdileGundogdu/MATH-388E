{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "Before you run your homework run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from urllib.request import urlopen\n",
    "from matplotlib import pyplot as plot\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.cluster import hierarchy \n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "assert os.path.exists('../homeworks/HW4.ipynb')\n",
    "\n",
    "info = sys.platform + '\\n' + sys.version + '\\n' + os.getcwd() + '\\n' + os.getlogin()\n",
    "name = hashlib.sha256(info.encode('utf-8')).hexdigest()\n",
    "with open('../other/hw-4-'+name,'w') as f:\n",
    "    f.write(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../other/hw-4-'+name,'r') as f:\n",
    "    info = f.read()\n",
    "name = hashlib.sha256(info.encode('utf-8')).hexdigest()\n",
    "assert os.path.exists('../other/hw-4-'+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Apply all of the supervised and unsupervised classification and clustering algorithms we learned so far for the [sonar dataset from UCI](http://archive.ics.uci.edu/ml/datasets/connectionist+bench+(sonar,+mines+vs.+rocks)).\n",
    "\n",
    "The code for downloading the data is below. Don't load the data again and again in each subtask, refer the data as `SONAR` after you run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urlopen(\"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\") as fil:\n",
    "    SONAR = pd.read_csv(fil, delimiter=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.3513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "5  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "6  0.0317  0.0956  0.1321  0.1408  0.1674  0.1710  0.0731  0.1401  0.2083   \n",
       "7  0.0519  0.0548  0.0842  0.0319  0.1158  0.0922  0.1027  0.0613  0.1465   \n",
       "8  0.0223  0.0375  0.0484  0.0475  0.0647  0.0591  0.0753  0.0098  0.0684   \n",
       "9  0.0164  0.0173  0.0347  0.0070  0.0187  0.0671  0.1056  0.0697  0.0962   \n",
       "\n",
       "       9  ...      51      52      53      54      55      56      57      58  \\\n",
       "0  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090   \n",
       "1  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
       "2  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
       "3  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
       "4  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
       "5  0.3039 ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027  0.0051   \n",
       "6  0.3513 ...  0.0201  0.0248  0.0131  0.0070  0.0138  0.0092  0.0143  0.0036   \n",
       "7  0.2838 ...  0.0081  0.0120  0.0045  0.0121  0.0097  0.0085  0.0047  0.0048   \n",
       "8  0.1487 ...  0.0145  0.0128  0.0145  0.0058  0.0049  0.0065  0.0093  0.0059   \n",
       "9  0.0251 ...  0.0090  0.0223  0.0179  0.0084  0.0068  0.0032  0.0035  0.0056   \n",
       "\n",
       "       59  60  \n",
       "0  0.0032   R  \n",
       "1  0.0044   R  \n",
       "2  0.0078   R  \n",
       "3  0.0117   R  \n",
       "4  0.0094   R  \n",
       "5  0.0062   R  \n",
       "6  0.0103   R  \n",
       "7  0.0053   R  \n",
       "8  0.0022   R  \n",
       "9  0.0040   R  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SONAR.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Öncelikle aynı kodu sürekli yazmamak için başlangıçta veriyi 2'ye böleceğim. Gerektiği yerde tekrardan ayırdım datayı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = SONAR.iloc[:,0:59]\n",
    "ys = SONAR.iloc[:,60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 1: K-Means Algorithm \n",
    "\n",
    "\n",
    "Elimizde bir sürü veri noktası var ve bu noktaları kümelere ayırcaz.Eğer çizdiğim grafik doğruysa k-means ile tek bir kümeye ayırmamız ile güzel bir sonuç verebilir. Bu yüzden ilk olarak bunu denemek istiyorum. Ayrıca verinin %25'işini test verisi olarak kullanacağım.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15 15]\n",
      " [15  7]]\n",
      "0.4230769230769231\n"
     ]
    }
   ],
   "source": [
    "Xtrain , Xtest , Ytrain , Ytest = train_test_split(xs , ys , test_size = 0.25)\n",
    "\n",
    "model = KMeans(n_clusters =2 , random_state=1)\n",
    "model.fit(Xtrain,Ytrain)\n",
    "predictions = model.predict(Xtest)\n",
    "transform = {\"R\":1 , \"M\":0}\n",
    "real = Ytest.map(lambda x : transform[x])\n",
    "cm = confusion_matrix(real,predictions)\n",
    "accuracy = accuracy_score(real,predictions)\n",
    "print(cm)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 2 : K-nn Algorithm\n",
    "\n",
    "Şimdi de elimizdeki veri kümesini sınıflandırmak istiyorum. Burada komşularına göre sınıflandırma yapacağız. Aralarındaki mesafeye baktığımız için normalize etmemiz gerek çünkü veri noktaları arasındaki fark büyük. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  2]\n",
      " [ 4 21]]\n",
      "0.8846153846153846\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(xs)\n",
    "xs = scaler.transform(xs)\n",
    "\n",
    "Xtrain , Xtest , Ytrain , Ytest = train_test_split(xs , ys , test_size=0.25) \n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3 , metric='euclidean')\n",
    "model.fit(Xtrain , Ytrain)\n",
    "predictions = model.predict(Xtest)\n",
    "cm = confusion_matrix(Ytest,predictions)\n",
    "accuracy = accuracy_score(Ytest,predictions)\n",
    "print(cm)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 3 : Naive Bayes Algorithm\n",
    "\n",
    "Naive Bayes algoritması da bir sınıflandırma çeşitidir. Olasılıkta kullanılan Bayesian Kuralına çok değişkenli hale getirip ve değişkenlerini bağımsız sayarak yaptığımız bu algoritma diğer yöntemler gibi kullanılan veri kümesine bağlı olarak iyi ya da kötü sonuçlar verebilir. Ayrıca GaussianNB Gauss sürekli dağılımını kullandığı için onu kullanmak kolay ve daha iyi sonuç verdi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  7]\n",
      " [ 9 18]]\n",
      "0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "Xtrain , Xtest , Ytrain , Ytest = train_test_split(xs , ys , test_size=0.25) \n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(Xtrain,Ytrain)\n",
    "predictions = model.predict(Xtest)\n",
    "cm = confusion_matrix(Ytest,predictions)\n",
    "accuracy = accuracy_score(Ytest,predictions)\n",
    "print(cm)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 4 : Linear Regression Algorithm\n",
    "\n",
    "\n",
    "Linear regression yaparak eğer datamız lineer şekilde dağıldıysa onu daha rahat keşfetmekti ancak aşağıdaki sonuç gösteriyor ki datamız bir doğru olarak dağılmamış. Çıkan sonuç bize bunu dedi. Eğer bütün sütunları alırsak sonuç daha kötü çıkıyordu. O yüzden hepsini almadık."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.433829\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "#to_drop = [column for column in upper.columns if any(upper[column] > 0.85)]\n",
    "X = SONAR.iloc[:,[9, 10, 14, 15, 16, 17, 18, 19, 20, 23, 24, 26, 34, 35, 36, 45, 46, 48]]\n",
    "y = SONAR.iloc[:,60:61]\n",
    "y = y.replace(to_replace=['M', 'R'], value=[0, 1])\n",
    "logit_model = sm.Logit(y,X)\n",
    "result = logit_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 5 : Hiearchical Clustering\n",
    "\n",
    "Bütün veri noktalarını 2'ye ayırarak kümeler bunu da aralarındaki en kısa mesafeye göre yapar. Daha sonra diğer kümelerle aralarındaki uzaklığa bakar ve en küçük mesafeyi alıp tekrar küme oluşturur ve böyle gider. Algoritma böyle devam eder. Ayrıca algoritma çalıştığında farklı sonuç vermiycek çünkü zaten aradaki mesafeye bakıyor yani uzayı değiştirmediğimiz takdirde değişmeyecek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26 85]\n",
      " [13 84]]\n",
      "0.5288461538461539\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXmcXXV5/98PSwATICxJHNCaIIgsyqARWVRGwRUrtIpLWosWm9pat7aitW7VarWL1bbWnyMooToIQhWXiigawQ0MZmTVsAgRM5lEhZAFMhCe3x/P9zAnN/fOPXe/9+Tzfr3mNfeee5bnu32+z3m+3/M95u4IIYQYfHbptQFCCCHagwRdCCFKggRdCCFKggRdCCFKggRdCCFKggRdCCFKggRdCCFKggRdCCFKggRdCCFKwm7dvNiBBx7oCxcu7OYlhRBi4Lnuuut+4+7z6u3XVUFfuHAhK1as6OYlhRBi4DGzu4rsp5CLEEKUhEKCbmZzzewSM/u5md1iZieY2f5m9i0zuzX936/TxgohhKhNUQ/948Dl7v5E4BjgFuAdwJXufhhwZfouhBCiR9QVdDPbB3gWcB6Au0+5+73A6cCytNsy4IxOGSmEEKI+RTz0Q4D1wGfNbKWZnWtms4EF7j4BkP7Pr3awmS01sxVmtmL9+vVtM1wIIcT2FBH03YCnAJ9092OBzTQQXnH3UXdf7O6L582rO+tGCCFEkxQR9LuBu939mvT9EkLgJ81sCCD9X9cZE4UQQhSh7jx0d19rZr8ys8Pd/RfAKcDN6e8s4MPp/2UdtbRBRkdhbKzXVoh+ZckSWLq011YI0V6KPlj0RuDzZjYLuAN4LeHdX2xmZwOrgTM7Y2JzjI3B+DgMD/faEtFvjI/Hfwm6KBuFBN3dx4HFVX46pb3mtJfhYVi+vNdWiH5jZKTXFgjRGfSkqBBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClAQJuhBClITdiuxkZncCG4FtwEPuvtjM9gcuAhYCdwIvd/d7OmOmEEKIejTioT/b3YfdfXH6/g7gSnc/DLgyfRdCCNEjWgm5nA4sS5+XAWe0bo4QQohmKSroDlxhZteZ2dK0bYG7TwCk//OrHWhmS81shZmtWL9+fesWCyGEqEqhGDpwkruvMbP5wLfM7OdFL+Duo8AowOLFi70JG4UQQhSgkKC7+5r0f52ZfQk4Dpg0syF3nzCzIWBdB+0UPWZ0FMbGem1Fexgfj/8jIz01oy0sWQJLl9bfT+wc1A25mNlsM9s7+ww8D7gR+ApwVtrtLOCyThkpes/Y2LQQDjrDw/E36IyPl6eTFe2hiIe+APiSmWX7j7n75Wb2E+BiMzsbWA2c2TkzRT8wPAzLl/faCpFRhjsM0V7qCrq73wEcU2X7b4FTOmGUEEKIxtGTokIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIk6EIIURIKC7qZ7WpmK83sa+n7IjO7xsxuNbOLzGxW58wUQghRj0Y89DcDt+S+fwT4d3c/DLgHOLudhgkhhGiMQoJuZo8BTgPOTd8NeA5wSdplGXBGJwwUQghRjKIe+seAc4CH0/cDgHvd/aH0/W7g4GoHmtlSM1thZivWr1/fkrFCCCFqU1fQzezFwDp3vy6/ucquXu14dx9198XuvnjevHlNmimEEKIeuxXY5yTgJWb2ImBPYB/CY59rZrslL/0xwJrOmSmEEKIedT10d/87d3+Muy8EXgl8x93/CPgu8LK021nAZR2zUgghRF1amYf+duCvzew2IqZ+XntMEkII0QxFQi6P4O7LgeXp8x3Ace03SQghRDPoSVEhhCgJEnQhhCgJEnQhhCgJEnQhhCgJEnQhhCgJEnQhhCgJEnQhhCgJEnQhhCgJEnQhhCgJEnQhhCgJEnQhhCgJEnQhhCgJEnQhhCgJEnQhhCgJEnQhhCgJEnQhhCgJDb3goheMXjfK2A1jDR83vvZjAIyc/5amrrvkSUtY+tSlTR0rhBC9oO8FfeyGMcbXjjP86OGGjht+R3NCDjC+dhxAgi6EGCj6XtABhh89zPLXLO/a9UbOH+natYQQol0ohi6EECVBgi6EECVBgi6EECVBgi6EECVBgi6EECVhIGa5CDFIjK5Zw9jkZMevM77pUABGVt7W8WsBLFmwgKUHHdSVa4nmkKAL0WbGJicZ37SJ4TlzOnqd4U93R8gBxjdtApCg9zl1Bd3M9gSuAvZI+1/i7u81s0XAF4D9gZ8Cr3b3qU4aK8SgMDxnDsuPPbbXZrSNkZUre22CKECRGPpW4DnufgwwDLzAzI4HPgL8u7sfBtwDnN05M4UQQtSjrqB7sCl93T39OfAc4JK0fRlwRkcsFEIIUYhCs1zMbFczGwfWAd8CbgfudfeH0i53AwfXOHapma0wsxXr169vh81CCCGqUEjQ3X2buw8DjwGOA46otluNY0fdfbG7L543b17zlgohhJiRhuahu/u9wHLgeGCumWWDqo8B1rTXNCGEEI1QV9DNbJ6ZzU2f9wJOBW4Bvgu8LO12FnBZp4wUQghRnyLz0IeAZWa2K9EBXOzuXzOzm4EvmNk/AiuB8zpoZ0eo9fKMbD30ymV09dILIUQ/U1fQ3f16YIcJte5+BxFPH1hqvTyj2ss09NILIUS/s9M/KVr05Rl66YUQot/R4lxCCFESdnoPXYiy0MlFwbK1XDq1BIAW/moP8tCFKAnZomCdYHjOnI4tNja+aVNXVqfcGZCHLkSJGMRFwbTwV/uQhy6EECVBgi6EECVBgi6EECVBgi6EECVBgi6EECVBgi6EECVB0xYHkdFRGNtxUbGOMv6x+D/ylu5dc8kSWKq1c4QoigR9EBkbg/FxGN5xEbFOsXy4i0IOkT6QoAvRABL0QWV4GJYv77UVnWNkpNcWCDFwKIYuhBAlQYIuhBAlQSEXIURdtJLjYNAzQa/1+rdKar0OrhK9Hk6IzpGt5NiJFRc7tYojTHcWEvQOU+v1b5XU+x30ejghuoFWcux/ehpyKfr6t3ro9XBCCKEY+ozkw0LVQj8K8wgh+gnNcpmBLCwEcTeRD/+Mrx0vNAYghBDdQh56HWqFhRTmEUL0G/LQhRCiJEjQhRCiJEjQhRCiJEjQhRCiJNQVdDN7rJl918xuMbObzOzNafv+ZvYtM7s1/d+v8+YKIYSoRREP/SHgb9z9COB44A1mdiTwDuBKdz8MuDJ9F0II0SPqCrq7T7j7T9PnjcAtwMHA6cCytNsy4IxOGSmEEKI+DcXQzWwhcCxwDbDA3ScgRB+YX+OYpWa2wsxWrF+/vjVrhRBC1KTwg0VmNge4FHiLu99nZoWOc/dRYBRg8eLF3oyRQvSaRpaPbXQ52J1peVfRWQp56Ga2OyHmn3f3/02bJ81sKP0+BKzrjIlC9J5s+dgiDM+ZU3hJ2PFNmzq2zrjY+ajroVu44ucBt7j7R3M/fQU4C/hw+n9ZRywUok/oxPKxO9vyrkVp1ws12vXyjEG5iyoScjkJeDVwg5mlV7HzTkLILzazs4HVwJmdMVEIsbPRrhdqtOPlGYP0koy6gu7u3wdqBcxPaa85QggRtPOOqFWPf3zTpqa9/G5693pSVAhRehoZA6mkkTGRSro9RjJwy+dWexdprfeO6gUUQoiMXrxCr9tjJAPnoedfOpFR+fIJ0AsohBA7HwPnoUOxd5HqBRSiH6mM5VabhTEoMypE/zFwHroQg0xlLLcyPqt56aIVBtJD7xW1XhqtWL1ohJliuZqXPjgUmTlTZB58O+/I5KE3QLWXRitWL8TOSZGZM/VmyLT7jkweeoNUxu8Vqxdi56XVmTPtviOToPeK0VEYa9KzH0+zfEZGmjt+yRJY2icholr5UC+N/ZQGIfoEhVx6xdjYtGg1yvBw/DXD+HjzHUknqJUPM6Wx39IgRJ8gD70Jag2OQoMPMw0Pw/LlHbBwBpr16jtJo/nQj2kQog+Qh94E1QZHQQ8zCSF6izz0Jqn2cFPXB0ibicO3En9X3FqIvkaCPshk8edG4umtxN5Bgl5S6s2p7vZ8atEcEvRBp1txeMWtS0299cfrrTbY6zXD1SEFEnQhBNDanOpeP+E66B1SuyidoGczUPRovigz1TzSnX2hr0HukNpF6QQ9E/P8zBOgYUEfvW50h05BiH6hmkda6YWWxesUxSmdoMP2M1CanXmSTT/M1msRot+o55GWxetsN0XvbmDw7nA0D30Gso6h8uUZQrSb0TVrGFm5kvFNmx55f+XomjW9NquUVFtUq9oiWoO4lHEpPXRRAmaaY9+FdV7qvYii3Z5bZQhF4ZLOUiTePoh3OF0V9PVb1j8SAmnpkXlRfmrNsZ+YmP5cbQ2YDRtmXuuloNhXCmzlSyig/WKbF5lBFBPRe7oq6L+7/3dsWLthh3eANjtw2S9Um1kDA9JJFX3atOgTpu18mrTaHPuREZicbO4BqQYfjqrlxUlsRb/S9ZBLXzwy32YqZ9bAAHVSRZ82LSKg3XqatNmHqXr0cFQ+fFNrauEgUeZBxUGn1DH0WlMPO/EauYF+8UUjAlnPox8fry6cJVgHJhOyRuPp+fBNramFg0SRKZPQ+XGAmTrKnbUjKbWg15p6mHnTReaqZ53CgtkLGNp7qAtW9zkzefQzrV8OAy/o1YSsqGg1Er4ZXbNmO4FqVJya7XgaoR8GFWt1lDvzgHJdQTezzwAvBta5+9Fp2/7ARcBC4E7g5e5+T+fMbJ7Mc857zI1402M3jLFh6wZNXcyzE69fnglZpXfYjPDWIjvv8Jw5TYlTKx3PoFGtY+nXMY5uhKqKeOjnA/8FXJDb9g7gSnf/sJm9I31/e8NX7zGVg5mj1432f8xb9AWdnmaYCVWz4lQpdP0qcnmKjDUMcofUjVBVXUF396vMbGHF5tOBkfR5GbCcDgp6rTcEtRr3zg9mZi+naIeg52P36iTKS6vTDPOhlQWzZjE0a1Zb7Zvpuv24DkyRsYZO29PpuHynQ1XNxtAXuPsEgLtPmNn8Wjua2VJgKcAeB+/xyPZGXuOWF95m1mjJC2xlLHz40cMsedISxteOM752vC3rtuTfWtSuTkI0QeUAbq2plz0asM2L6uTUVNcEvZ/Xgen0VNF64xO9jsu3On7S8UFRdx8FRgH2XrS3Z9uriTTUFupWZpHkBXZy8+QOg5udWLdFMfc+oHIAt9qgbY8HbCtDNnnyjXt0zZq2isnOug5MkfGJXsblWx0/aVbQJ81sKHnnQ8C6Zk7SzTnplZ59LVsavb7CK31OvQHcNgzYdkp48x782OTkQMeP+4lWxyeKUm/5CKgexmnFvmYX5/oKcFb6fBZwWZPnAUIIR84fYeT8ke1CHyPnjzB63Wgrp+44leGVjImNE4+kpd/TIFqjUnjbSbV48s5G1mGOb9o0UAuWVS4CVi2M0+76UmTa4oXEAOiBZnY38F7gw8DFZnY2sBo4sxUj6oVf+o2JjRNMbp58RKirhVcmN+caeatx9FoP8/RZTHhnodIjhx1j0LUG1+rFRLNzd3OQtN/p9Z1KK3HtmUJbM3ng1epYEYrMcnlVjZ9OKXyVAgzSkgBDew+x6nertvPIq9G2OHqth3kajQlX6xhmWqNFHUNVinjk1QbXisRExyYn2bBtG8NVxLwdnUQ/Uu1BqMo0Fb1LKSq+1cJktY5tNa7dDM3e9ZX6SdFG6eunQos+zDNTTLhax1Dypzs7RRGBafdc8E50Ev1AO+f0FxXfal7/TMdWxrXb8TRvveObCbWVVtBnmqpYi2afCs1CMNl1+5p2dAwlp9XG2kkG8YGhIrRz6eBag4qV4axqgll0QHIm8S9yx9Epr79v31iUCfL42nEmNk5st71y8LSaiFZOVewklfHynjE6Gp51tkDWaJ93Lnl7+8jWysY2aG+taYX8m5Ou3biRuVdfPZBvT6o2kJrdqeTHJiamppoebM3Ev7JjqLyTqlWHah3fCn0r6LUEuXIANXvCsxqVg6ydpJvXqkkWHx8envklD/1C3r5u2zo6Gp1ejQ6wsrHlBWJiamqH02XCMGgzMSrJi9EsMzZt29bVTi2fz610JEVj0EOzZrFh27ZC6ctsq1b+lWT1p92CXY++DrnUmjvejpdANxOSGQiykEorIZPMc84+dzKO3syLKtpB5XhCnTGDek91TuYaeaU41LoF7wTtmBPfrXna1agWiihKkZBKPSamph65Q8nOmbetn8cioMuC/uC2B/tmXna9p0d7RiMzUYrOQsnOmT/PTMdWes7dHhhttUOpll7YMc358YQqHWAtgaglNLUEpNagXyfo9RS/dtBsh9IOwZ2cmmJyaqpwuK2dD5W1Y22froZcdt91dzZs3dDbOHOOnoRJqt3q52/380L0iKHDO3qyjYRU8t5o0XBMtWs2QpbOmdI6k73VPhelMr1QO82V5ZGzrVrMtVm6eQuuh5FaY3jOnEfuoOqFWNr5UFnlXWAz9HXIpZRUmzpYebtfayZKtcWm8t7nTNTxRndgYiLe3Zldt1EvuZqoZjZD/fO1GoqpzMNaac7bmYn+057W2rW7RLXZOINEZSiqaLy82nG1POOJ5HE3GotvZOG0dnaerd7FSdB7QVGxqaSeSGZkIYvKBl4ZiphJqPPeRrNhl1ovee4mRdLcjnGHHtBKvLlTNLL8bD4U1cjAa7Xjagn60KxZrLr//qa853aEyOpNgW33k8E9neUysXFiuymI/RBb7zqZ+E5M1N8XpsUn/1fpzY6NwYYNMDS04/b83UGnwy79QKNpbgNrujjjpRNT31oh7zlXPgDVzql7/ZbuPPmpkPWmwLYzrAc99tAnN08yuXmSBbMXsOp3qzjnW+cAxdY4Lw2Z+HZLOHvpjVYOdtYjC/u0OtOmMs15OxYsiI4vv21iYsfOsAHWzTDjpVnWTE09ct5WwivNPjS1Js3+ALh240amHn6YuVdfvZ2gZjZVe00fTL+qL79vpU2NeKrNrnfSaSrvCro5a6jnIZdsUDKba97IQlb5qYfteDFFKakmXr2i0cHOoSFYtar9M23y156cjOvkt61b13I+1fIcm73FzsS81fBKs08orksdSjY/vXLIrppN9V4WUWkT1I9X5zu2iQ50nJ1gpqmQ7abngp7RzGyTTryYoqd0Yv53NfHqNPl0VE6RbPZOpOjUy1p3AZUdW+X881Zsa4BWptY14unNNBjYrMdYeVyRJQgqlyrIPziU79SKxqvzdz/Z9MJ+J5sKuSB57ufcfnvHVtPsG0FvlmZfTNGXdGr+d6V4zSS4tWhkLnuWjgUL4Hvf23HQthmKPgg0NgZTU3D//XDOOdN3Jb3o2BLNzrRohXqDgdXCFc3MOKlFvZULYWZvfKY7mW7M52+ErHyhdr5lNmf7deqVg3376P9Oy/BwiFAn1zdpZomAvKBmQn3OObXnlQ8Ph2jutVeMEZxzTvGB31rkB4Rn8qZnzYJ9943PeUHr0SBvI4+Xd4vK+dOVDz/V6wjyA77VlkWYaTCwyDz5dg8WdpKZnhKupNPPCEjQ+5GhoRDBIkKbX+CqEcHMD6oV7TwyQR0aCsEs0iHUEtdOU4YZOh0mWx89E+IiM0eqPUhT64GY/Prrg77GTT365WGuvgq5VL4JqCilXZelCM2GEiYn42/Bghh4PCdmGBUO8zQyW6ZavLoZJiamr9doyKjENDvQOlkRjx6aNavQjJNay87C9mGQbsaORdBXgl70TUCwvYjnl9ftq3VZ8jTyUE+9YyufDm1WMLPjMg+r0bh9OwZx80+kZuJci6wTqnykH3ZqQW91oBWmhbiRGSeNnL/TsWMR9JWgN0Ll4lq1VmbsG6o9Yl5UhGZaLqAdFAlN5OeE5+3Kf25GVDMByeLy9eaAN/uUbUnoxjtHOzHo2G8DmWVloGLomVeeeeR9sQZ5I2Ri1EhsN+8FL1kSx2debKuDjI1QK66fxeJbealGNoCaXacIMyyqVWb6ZbCwlRdDiM4xUB56s6+I6zUvXr4GxtfFl9HR6t5uLTIBzWaKZNva/XRpIzblyTzs7M6jG4yORl5s2ADz58eDQFneiK7QyhoponMMlIc+qJz643XTX8bGGpvFAiGWJ5/c2DGN0qhNeYaHu3vXkNm4776wdev0LJp+f0OTEB1moDz0gabsU+h6sSYN7Di2IMROjDx0IYQoCRJ0IYQoCRJ0IYQoCS0Jupm9wMx+YWa3mdk72mWUEEKIxmla0M1sV+ATwAuBI4FXmdmR7TJMCCFEY7TioR8H3Obud7j7FPAF4PT2mCWEEKJRzN2bO9DsZcAL3P116furgae7+19V7LcUyJ4JPxz4RfPmCiHETsnj3H1evZ1amYduVbbt0Du4+yiwczyXLYQQPaSVkMvdwGNz3x8DaGEHIYToEa0I+k+Aw8xskZnNAl4JfKU9ZgkhhGiUpkMu7v6Qmf0V8E1gV+Az7n5T2ywTQgjREE0PigohhOgv9KSoEEKUBAm6EEKUBAm6EEKUhNKth54ecDJgX+B+dz+3xyb1BDN7HfE0L8Bl7v71Xtoz6JjZU4BnAI8GbnH3/2nTeV9FTPn9JHCCu3+rHefdmTGzdwGbgDnAVnf/l9xvrwHmp6+T7r4sbf8UcBnwTXffVnG+l6ePJwE/cPeLO2j7i9LHpwMb3P2jjRzfdUE3swOA37m7m9mZ7v5FM5vj7pvSb68jHlA6CfgB8C/AU4BV7r4xncOA/ZmeB38HcbexjWhwBwB/B3zNzBYD96Xt+xIF8s81bJsD7AH8Dtgb2Jjs3Cf3eW7afdcsHfnj3X1TxTnnAttytp8HrAY+DXyAeHI2e4L2/+WuMwc4NJ3mZ2nb7sBRwEPAHe6+xcz2A+4Fjgbucvf70jUfC7wFeFM6/9fN7BzgROCJwJ3AOuAeYHb6PJl+/w7woLt/JuX1MZkd6fNDKc+PAFYR9WgKOAS4K6V3s5kdlI6byJdhlp/pXI8CfgScAJwKPADcD5wCrASOBdYC73L339Qot7kA7n5vbtt7gWuAv07n+zYwF/jHijK7KKX30uz8ZjY72b878EXgh8AzU3mcAPxtrh5syOdPKqcDyNWhlL9ZvZpdUUcOAz5KrIu0p5k9O5XDsippsqweuPuDKX8zcbo12fxIHcy3tYr8qlZPt9tWmadm9naiXb4E+DlRX14AfCqfd7ljH6nzFdfZh+nIwIPuvjlXDsuBL+bK4U3AnkzXh9tSXp0CfDVnW75eXwIsJNrRX5jZe5PtRxOasZu7P9/M3gi83MwWEO1jCng58AYzu8bd358z+whgBdHOflwlTQcQ2rMNeDywF/FMzup03buIenAicH0+X1J+PCWl81nAk4BvpGs+yswuqFXvq9GVWS5m9hKiIgwBTyMqww3A84HrgHnAAmJu+1yiIS8kCn5r+rwbIe5HExkAkXk3ESJ3IJGBPwX+lBCzJcD70nH3ERXxHuBBonL+IXB1sml3YEu6/r3ARcCfEAX4IuD2ZNfe6dgnER7Ab4jOYjUhTncDv0rnfDTwXeBlhGjsChxPVMq/JsTrhmT/unSuY4l1cZYQHsPPgL8gBPhJ6RzriIZ8I/AwcBDRIRyZbMjEdg+igo8AYyndWZ49j6jg3wZeCvwDISq/TWk/G7g5XW898D3gL4mKOied50qiEWWiZenzXsDvEQJ2ALA5le1T0rY5qbz+l6jEc4FLUz7flvLkZcBnUxlsITqFLJ9vIjr8u4jG/bV0zlPTdQ5J+fOTVK6HAV8lxHgtUZeemGzZls6/OdmclePRqcxOAv6dqIenE53Eq4Cr0r4vBM4j6tsuwJeBPyDq2/pkS5Y/U6nM902/H5TS+8ZUBkuITv3Pku0/ITqLi4APpfRfT3Qs61Pe3p3y63Si3s1K5bCeqIN3EM7NC1Oefjnl05cIEXkFME7cfdxI1KNnEfX90JRXK4Fhol4el/LqIsIh2UDUmcOBX6dzPJtoI/sSHf77gLOIuvr09P9n6ZqTqRyPA/4r5eNUOudjiTq2majDt6Ry2ysdv3ey/RbgNcmm3wcWJVsen8rp4XStX6Qy2pDSNUTU/7MJB+n41LF8Cfhzph2WBwh92kI4M9cTndkUcHGyff+U3q1EvXosUY9+nMrwjrTPfMKBMeAJKW+fR2jOPwBvJTowgH9LaZnn7u+hAN2KoT+fyJxricLbjxClC4gGtoZI2H8TmXA6kdHriNvR24iGuZDIyLlEpk0RBbMJuJWocA8TFWgWIZBnEWJ4INFgTiQa7kKiYCEqzwPJlh8RInYKUeEfn86zkmhQhxOdwm5EoVxGdEq/TvY8mehU9iYKd3U632/TObYQgnQZUek3p31+S3Q41xIVlpSe30+2/SBddy1wYcozT7bNB84lRONRwJvTNX7g7n9JCJ4RlXEYeBewD1ExT0h59qdE5SWl4WdEhbqWEOLdUzoeSHZsIjqr/QjBvImo0POANxAic2PKi7VEw9ya8u3TqbxuTvbuSojXFqIyn5TOfyfRCd2fzvMQ0WkdlcriKqIOTxJ15Ubgcyn/VqVr7pLO8ah0vkel3+4mGuP6lIbZqSzmEx3N94lOYKW7/7O7f5zw0i4AfpnK7HCins0iyn4NcHC6/m6EwGxL6f9MuvZ9qVy/nM53GdFoD0vX/CjRea0jRPgU4u5gDtEOVqT0/iqlwYm6/KNk11RK77WEKB8InAGcltKfdba3E6KzOaVpkuhAH0p58cZk9wTRme+f8v6YdMyCdK0903U/k+xfRNSn6wkx+zbwT0Q9OyTl1WyCO1Jeb0z5tTrllxPtPBO2e1Paf0B0/KvStoOITueBZMfRqSwXMAilAAALa0lEQVQ/C3wdGHP3VwKXE/Xpx+m47xOd3HdT2n8O3Jm89gOIOvzDZNcqol5tTWWxW8qH/0j5/4SUnzcTdenhVBaZV31r+jw7ff5lyo8np3LLOreHCMft+4TT8Dfu/jV3/8+U7kJ0y0P/W6IXPJhovJcTlTvLiKcTmTNEFOjlRAfwTGIdmCuAq9z9XjPbk+ggdkt/G4nK/lKiou1C3LZ93cz+i/BMP5DOuwr4fDpmd+KW70Yze36y65mEKO1NVMwrgPMJj+YaonKfSohiZm/WsawiPOhxd/+Omf0h0UjvBt5GiM+LicZ2OdEwDgJeTTTiHxON7biUnr2BDxOFfYO735PCK2cSgjiPEJ+7CIFbC7w+5eVD6XwXuPutZnaou99mZm8FnktUuBOJxvU14I8IgXlfsvdoQpBvT3bPJsTpdkLEfgKcTHSIdxKNaQPRaG939zvN7BCiAU+l49emfQ8mKv5QyvNbic7lRcm2SwiPZRdC1E4lGvaHUjmuSGV9BSEqCwkv7ckpb68m7oJuJxrqK1Ie3Ud0FD9K9sxP5TlCCPF/Ep3nJUSnkN19/YG7XwhgZouIzu0nhBcLcXv8e+nvimTv01J+7U/cJZ2SjtlKOAjXpDR8GXiSu3/KzC5M+z8ELGZ6XaRVKR0/B5a5+2/N7GhCCOYzLYA/TOX2XOBbwOOIunSxu99gZu9ONm8j6uWNTHdiNwNPcPeXmtkxwDuJ+nNcSu+yVO7/Syy0t4hpD/5BojMwQqjuIByKdxNil5Xjriltx6fjf8W0CG4B3kOI/9+ncx6Zymy1uz/bzG5MZTtJhGW/Q3jmKwhnZH+iPj9EOEevI9rutURdXZzSeg/wMaK+3Uk4jE8lYudvNbMvEnV/b6Jtf56oj0cR9WQ+Ua/3TWV+F1EHf0G01f1T/j8qbcvS95yUD/e6+0/N7D3JpjuJu47V6byLiXb/JMIBNOBEdy+0km23BP3v08dtREVeB/wfIU5biEb2R4SH/gxSrJvwUKaI3vkIojAPJkRgNiEkvyEa8/2ER3Y0EYvL4rZbiEx5ASEqW4nM3pLOeRuRkbukz08gKsIuRIX+cbJzHVFwuxKN6WCigH+ZbL6a6TDRw0RPf2+63k/Svr8lKusBhPiNu/s7zewqouN5bLJrGxFq2ECI/Ox03j2JCnk/0Si+n871RKJBH8j0bffKdPwewB8Tlf/6lOZvJps3EgJ+OuGtbAGe6u5LzOwCosF+gQi13E5U4PuSPZlNu6Y07ZL+fkQ0hqPSvtuIzvNXKX13EA3r4FR2R6b9f5Zs/Arw8XTdRcm2qwkv8amprK4g6sulKR1b0t8BRN34A0Is35LKcgEh1C9NeXNZStNfEZ3EN1I65hEN/AGmRedB4Ep3/8/kwWWiezhRj44gGuVjCWGdTGW+mQirneDul6axk2MJIXomIdT7pPM8h3B4diHuiq5M5XFsyjuIujWL6fq6Ol1vUdp2JHGn+EBKw4Wp7F9BdAZzk73jhKDvR3Q6f5bs/AhRhzJnZhZR948n7r6eSLTZqwln5EeEA7GACBW8h6irfwy8P+XdBFHnD0rl9Nb021FEJ3EWcWdrKS0bmR472yPlx9sJ5+OMlI6FqQx+Tgj1L1MZrQf+BvjXVI77AGtSHP1E4FXu/kYz+xxxt3cdoRt7EZpxk7t/xMy+QHQG1xAO44WpHPYk6s+lRD37PNFxfSWXn2OE0/ZtQjvuJzqH7PM+THe+Twf2cvcXpfGek4h6NEGE8Ba5+/cAzOzJ7n49BehWyOVGohAPJnrxc4kMuIso+EOJBv0KQgxvJhr+V4lCXp+O/U76fSFRIIcQorWRqKwPEAV8ZTrnasLb2oOovFcRlXTX9H83QhR/nfu8krgDOI0ouJOJCreWEOaLiAJbRlTkjxCN75/T7xen619OeJV3J/u+QQyI/Le7fwB4sbu/M+XPpYTIzCPWxDmYaERvIbyEu9L1NhKV4oWEWB6YbHmAaCyzCdH7eMqPlxLe//kpnzcCv3T3z7n76939bSmUcFna/m8pvyBiuc8gGs/1hEj+LqU1b9NU7vODhMf0M6ZDGr9J+2fHjxNiNpTKeXP6+xBx5/Nc4K0pzPEXREf8D8mOQwhhv4wQ8OOIunRPKqN3p2Nen67/Tykv3sB0mO8cQjDelvLwZ8Tt+TtTHp2btmU2Z14XhNh9gBCYzMtdl0vbb4h680SiXn4XOM/M/o9o6HsSArd3sv8aos7/CSHC42lgMgtRfJUQnEmiPlnKu7tS+X47t+1GQti3EeGFvdJ59yTqxoFp312J9vBDojO5j+jYfpns/iVRx96fymKru78m2fKP7v5dYvD3Gnd/LfCv7n5NytPnpjQ/j+jUPpry+TTiTujc9Ntcog7PJpy31en/h4j49WdSPl3j7ncRbfn7RN08FNji7m8j6s1B7v7HwG/c/WHCIz8X+E6qC7j7D4FvJ6/4n4gO+ntEp/Wwu/9J+gxwYSqDTxMatF/Kr/9O20cJ5+YJRLvI5+dziVDgLkQn8Lzc532IunRU2vZ44EQzu4TojO8H/ofw4FdnYp7sLyTm0OeP/qeedYoQuSxG+Rqi8nyIqGQriAza3d3PNrO/d/cPptHrMwkPZwpY7u43mdlRRIdwJ/Asd/+kmWUF/0kzOy1d/m7goXTMn6dtmSe6gGjkVxCV8QSmPfP877ekbb9292/OkM6nuPtP0+fnu/s3zezpRK/9C8KDupoQ/NlEJbojpe0BQiB+SjTOhe7+iXSuZURDX0TEgj+dnb9gEZBu1U9KXzNxWZaz6QCiQl6d8mEj0RhPJLzklxEiczcRBriR6QbhTMegLyfdjTViXzsxs8OIW/EDibDJ5mTj95KHfrK7fy/Voeckm9/PdFx4T0KQDiHE9Srgle7+d2b2rwDu/rfJ04fo4DMv7I0pXlppU9YGXkSIy3qmZ13sm9v2BGJGzgRxV/CJ9C6C3dPn04j6/M2K85/O9BS/lxAe50tSW/oc8Fl3vzJrVzPkXZY3xwB/6u5vNrMPEB3e9cCp7v5uM/s40XE+QHTWm4k6cTThZE1l9Td37nxbPpwIqV5Zyz4zO4Koi/Xa3VGe1p8ys9M8N7U3a5PpXK8DrqhXL1P9eR2hUwcQDsc30ufDiY73eCLM+TAw393fnY79c3f/1EznL0K/z0N/I+Exn0qI0g8Iz2gvwnNeRHhFJwF3p+lJ2dzrjzEdgxoBnmFmK4mB0d0JcV5kZr+fjid9fhzRGLcAR5jZmuz82THJjscR3tV/VJ4z/Z4dcwERNpipMrwt2WaEEH6T8M7HgQ+mc25lWlh/QDS+ajbta2bZjJOnE97pj1Na9s+dvyi7EHdDuxCV9eEaNm0lPJFr07ZsVsc8oiKvJIRoNeGtzkvnzY7fxnTe90TQCXEeZ3qmRJanuxMx9tenjjYr77Nz+52QzrGF6bI/m6hjxzBdx45kOp0npvNl5b6DoDPdBv6Q7evWU9ixvj2N6Xp9Wu6ap1E7b1+Zzp+l6anA7qktjQDXW0z9PY6ZyefNoiRu27UbM3sq29fh7PfD07V/mq75ie1PvV1bfjFwR7JpB/vSWES2b712966Kdpd/VuNtSczXEHl3aJ1zQdSf7JgsnQ9XpHNRyo+srW7MXb9lQcfd+/YPODn7D7w2fX4tEfvaYVv6/OT8sdm2inNVO/61uX2z30+e4ZpPzn2udc7tbKqXzmr2z2DnjDal729K/0eADxaxpYptp6e/XYhbwg/OYNObkg0jxGAcRJzx4nT8xen4EeB/auV9n9W3R2xqoA7VqqM71LHKcm+1DdS7Zp3zZ8dn6X1tPfuatLPa7zXbSkU+vbbG56rtvtF2l/8tl6ZC9bLimEbbalvqfV+HXIQQQhRHa7kIIURJkKALIURJkKALIURJkKALIURJ+P8l8OVydwE//QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = SONAR.iloc[:,0:60]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "linked = hierarchy.linkage(X, 'ward')\n",
    "predicted = fcluster(linked, 2, criterion='maxclust')\n",
    "dendrograms = hierarchy.dendrogram(linked)\n",
    "labels1 = {\"M\":1, \"R\":2}\n",
    "real = ys.map(lambda x: labels1[x])\n",
    "cm=confusion_matrix(real,predicted)\n",
    "print(cm)\n",
    "accuracy=accuracy_score(real,predicted)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 6 : Logistic Regression \n",
    "\n",
    "Supervised learning olan Logistic Regression'u elimizde veri topluluğu olduğu zaman kullanıyoruz. Linear regression'daki mantığa benziycek algoritma yalnız burda datayı eğri ile ayırcaz ve o eğri 0 ile 1 arasında değişecek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  6]\n",
      " [ 5 23]]\n",
      "0.7884615384615384\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(xs, ys, test_size=0.25)\n",
    "model = LogisticRegression(random_state=0)\n",
    "model.fit(Xtrain, Ytrain)\n",
    "predictions = model.predict(Xtest)\n",
    "cm = confusion_matrix(Ytest, predictions)\n",
    "print(cm)\n",
    "accuracy=accuracy_score(Ytest,predictions)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
